{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Indexing - LSI using Gensim\n",
    "===\n",
    "\n",
    "This document implements Topic Indexing using a gensim implementation of Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "import os\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare corpus\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\users\\avour\\Documents\\GitHub\\topic-indexing-lsa-gensim\\my_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "directory_path = r\"c:\\users\\avour\\Documents\\GitHub\\topic-indexing-lsa-gensim\"\n",
    "corpus_name = \"my_corpus.txt\"\n",
    "corpus_path = os.path.join(directory_path, corpus_name)\n",
    "print(corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = set('for a of the and to is has they be are as from their in'.split())\n",
    "\n",
    "# Generate Dictionary\n",
    "with open(corpus_path, 'r') as file:\n",
    "    dictionary = corpora.Dictionary(line.lower().split() for line in file)\n",
    "\n",
    "    # remove stop words and words that appear only once\n",
    "    stop_ids = [dictionary.token2id[stopword] for stopword in stop_list\n",
    "        if stopword in dictionary.token2id]\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq==1]\n",
    "    dictionary.filter_tokens(stop_ids+once_ids)\n",
    "    dictionary.compactify()\n",
    "\n",
    "    \n",
    "# Corpus Streaming\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        with open(corpus_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Assume there's one document per line, tokens separated by whitespace\n",
    "                yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "corpus = MyCorpus()\n",
    "\n",
    "# Save corpus and dictionary\n",
    "corpora.MmCorpus.serialize('something.mm', corpus)\n",
    "dictionary.save('something.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used saved dataset\n"
     ]
    }
   ],
   "source": [
    "# Corpus of documents represented as a stream of vectors\n",
    "if(os.path.exists('something.dict')):\n",
    "    corpus = corpora.MmCorpus('something.mm')\n",
    "    dictionary = corpora.Dictionary.load('something.dict')\n",
    "    print('Used saved dataset')\n",
    "else:\n",
    "    print('Please generate data set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement LSI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI topics: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize tfidf model\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# Use tfidf model to transform vectors\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "# Perform LSI tranformation\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) #Initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "\n",
    "print('LSI topics: ')\n",
    "lsi.print_topics(2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus LSI\n",
      "Topic :  1\n",
      "[(0, 0.2262602964370215), (1, 0.41505425844925259)]  # Teaching computer programming has long been known to be a complex process.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.25027660053480089), (1, 0.32718116265432917)]  # Software Visualization (SV) is the use of graphical and textual formalisms to describe the execution of computer programs.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.36000280527432388), (1, 0.38302786637597586)]  # The approach of using SV over a network as an educational tool raises futher issues as to how SV can be most appropriately included within a computer programming curriculum.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.28215966245084551), (1, 0.22003522668466413)]  # Some SV designers have claimed their product applies equally well from novice through to expert.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.37630383510885301), (1, 0.2368123633669173)]  # Recent SV evaluation studies suggest important differences in the way novices and experts are able use SVs.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.61574514122530544), (1, -0.23728393427964833)]  # Our students are studying part time and are required to fit their studies around other commitments, which means they will tend to study at different times.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.30069249679499016), (1, 0.5155496617012485)]  # Though many claims have been made by SV designers for the educational suitability of their product, little has been said as to the stage in the learning process when particular visualizations are most appropriate.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.43240018500997351), (1, 0.3356247292330255)]  # There is a wealth of evidence to suggest that the kind of knowledge structures and strategies used by expert and novice computer programmers differ qualitatively rather than quantitatively, and this affects how they are able to use different kinds of SV.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.68128885353702073), (1, -0.42778774491220617)]  # Students therefore require systems which are easy to use, low cost, multiplatform, and accessible from anywhere in the world.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.69824283671337528), (1, -0.42508249012469512)]  # The exercise asks students to write a sorting program, called qsort, which uses the quick sort algorithm.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.71392436783071134), (1, -0.1805965338007931)]  # SV is a method by which students and the tutor can communicate their understanding of a program, as well as solitary working.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.079243835388160933), (1, 0.62001511199483605)]  # The field of Machine Learning is becoming more popular.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.079243835388160933), (1, 0.62001511199483605)]  # Aritificial Intelligence and Machine Learning should be democratized.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Corpus LSI ')\n",
    "with open(corpus_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        topic_index = max(corpus_lsi[i], key=lambda item:abs(item[1]))[0]\n",
    "        print('Topic : ', topic_index)\n",
    "        print(corpus_lsi[i], \" # \" + line)\n",
    "       \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsi.save('/model.lsi')\n",
    "#lsi = models.LsiModel.load('/model.lis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
