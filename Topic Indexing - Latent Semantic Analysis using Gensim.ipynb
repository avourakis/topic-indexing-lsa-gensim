{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Indexing - LSI using Gensim\n",
    "===\n",
    "\n",
    "This document implements Topic Indexing using a gensim implementation of Latent Semantic Indexing (LSI). It is meant for my own educational purposes. \n",
    "\n",
    "**About the data:**  \n",
    "The data has been curated by me. Each corpus file consists of exactly 10 documents of a single sentence each. The first five documents belong to one topic while the last five documents belong to a different topic. The documents come from wikipedia and contain no typos. \n",
    "\n",
    "\n",
    "**Goal:**  \n",
    "The goal of this experiment is to see how well a gensim implementation of LSI performs when doing topic indexing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "import os\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare corpus\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\users\\avour\\Documents\\GitHub\\topic-indexing-lsa-gensim\\corpus\\corpus_2\\corpus.txt\n"
     ]
    }
   ],
   "source": [
    "directory_path = r\"c:\\users\\avour\\Documents\\GitHub\\topic-indexing-lsa-gensim\\corpus\"\n",
    "corpus_name = r\"corpus_2\\corpus.txt\"\n",
    "corpus_path = os.path.join(directory_path, corpus_name)\n",
    "print(corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = set('for a of the and to is has they be are as that by from their in'.split())\n",
    "\n",
    "# Generate Dictionary\n",
    "with open(corpus_path, 'r') as file:\n",
    "    dictionary = corpora.Dictionary(line.lower().split() for line in file)\n",
    "\n",
    "    # remove stop words and words that appear only once\n",
    "    stop_ids = [dictionary.token2id[stopword] for stopword in stop_list\n",
    "        if stopword in dictionary.token2id]\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq==1]\n",
    "    dictionary.filter_tokens(stop_ids+once_ids)\n",
    "    #dictionary.filter_tokens(stop_ids)\n",
    "    dictionary.compactify()\n",
    "\n",
    "    \n",
    "# Corpus Streaming\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        with open(corpus_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Assume there's one document per line, tokens separated by whitespace\n",
    "                yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "corpus = MyCorpus()\n",
    "\n",
    "\n",
    "# Save corpus and dictionary\n",
    "corpora.MmCorpus.serialize('something.mm', corpus)\n",
    "dictionary.save('something.dict')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used saved dataset\n"
     ]
    }
   ],
   "source": [
    "# Corpus of documents represented as a stream of vectors\n",
    "\n",
    "if(os.path.exists('something.dict')):\n",
    "    corpus = corpora.MmCorpus('something.mm')\n",
    "    dictionary = corpora.Dictionary.load('something.dict')\n",
    "    print('Used saved dataset')\n",
    "else:\n",
    "    print('Please generate data set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement LSI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI topics: \n",
      "(0, '0.485*\"science\" + 0.485*\"computer\" + 0.484*\"study\" + 0.389*\"algorithms\" + 0.219*\"an\" + 0.213*\"would\" + 0.124*\"basketball\" + 0.073*\"nba\" + 0.070*\"30\" + 0.070*\"member\"')\n",
      "(1, '-0.562*\"basketball\" + -0.303*\"states\" + -0.303*\"association\" + -0.303*\"united\" + -0.277*\"1946\" + -0.258*\"30\" + -0.245*\"national\" + -0.227*\"nba\" + -0.202*\"with\" + -0.188*\"member\"')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize tfidf model\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# Use tfidf model to transform vectors\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "# Perform LSI tranformation\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) #Initialize an LSI transformation\n",
    "\n",
    "# IMPORTANT: Once the transformation model has been initialized, it can be used on any vectors\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "\n",
    "lsi.save('model.lsi')\n",
    "lsi = models.LsiModel.load('model.lsi')\n",
    "\n",
    "# Print topics\n",
    "print('LSI topics: ')\n",
    "print(lsi.print_topics(2)[0])\n",
    "print(lsi.print_topics(2)[1])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Final Corpus\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus LSI \n",
      "Topic :  1\n",
      "[(0, 0.17571545262164923), (1, -0.83769662872329098)]  # The National Basketball Association (NBA) is a men's professional basketball league in North America; composed of 30 teams (29 in the United States and 1 in Canada).\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.14619065931030154), (1, -0.75391459295846031)]  # The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.23858201717555549), (1, -0.71312447978183968)]  # The NBA is an active member of USA Basketball (USAB), which is recognized by FIBA (also known as the International Basketball Federation) as the national governing body for basketball in the United States.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.22569695693714861), (1, -0.40468942550040343)]  # The NBA announced on April 15, 2016, that it would allow all 30 of its member clubs to sell corporate sponsor advertisement patches on official game uniforms, beginning with the 2017â€“18 season.\n",
      "\n",
      "Topic :  1\n",
      "[(0, 0.12968018211686858), (1, -0.4769110225415405)]  # The NBA originated in 1946 with 11 teams, and through a sequence of team expansions, reductions, and relocations currently consists of 30 teams.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.83230208514717385), (1, 0.22002621631451502)]  # Computer science is the study of the theory, experimentation, and engineering that form the basis for the design and use of computers.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.76288782413623812), (1, 0.11726869338167009)]  # An alternate, more succinct definition of computer science is the study of automating algorithmic processes that scale.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.59579228071477663), (1, 0.053337385487388388)]  # The earliest foundations of what would become computer science predate the invention of the modern digital computer.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.73327909012287518), (1, 0.21555740802680678)]  # As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.\n",
      "\n",
      "Topic :  0\n",
      "[(0, 0.60172032733938607), (1, 0.19660361426482559)]  # Data structures and algorithms is the study of commonly used computational methods and their computational efficiency.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Corpus LSI ')\n",
    "topics_index = list()\n",
    "with open(corpus_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        topics_index.append(max(corpus_lsi[i], key=lambda item:abs(item[1]))[0])\n",
    "        print('Topic : ', topics_index[i])\n",
    "        print(corpus_lsi[i], \" # \" + line)\n",
    "       \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obeservations:** There is no need to know what words belong to each lsi topic, we only care that documents of different topics are not assigned the same topic. The corpus consists of 10 documents (one sentence each): first 5 documents belong to the first topic while the last five documents belong to the second topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure Accuracy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0% (Ideal similarity is 0%)\n"
     ]
    }
   ],
   "source": [
    "# Check similarity of documents. It assumes the first half of the documents belong to a different topic than the second half\n",
    "\n",
    "similarity = 0 #0: no similarity, 1: exactly the same\n",
    "index_sum = 0\n",
    "\n",
    "for i in range(len(topics_index[:5])):\n",
    "    index_sum += topics_index[i] + topics_index[i+5]\n",
    "\n",
    "if(index_sum == 0 or index_sum == 10):\n",
    "    similarity = 1\n",
    "elif(index_sum == 5):\n",
    "    similarity = 0\n",
    "else:\n",
    "    similarity = index_sum\n",
    "\n",
    "print('Similarity: {}% (Ideal similarity is 0%)'.format(similarity*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
